# YOLOv11와 YOLOv12 : 미래형 객체 인식 모델 비교 분석

## YOLO 시리즈

YOLO(You Only Look Once)는 실시간 객체 감지를 위한 딥러닝 모델로, 수많은 버전을 거치며 **정확도, 속도, 범용성**을 점차 향상시켜 왔습니다.

| 버전 | 출처 | 주요 개선점 |
|------|------|-------------|
| YOLOv1-v3 | Joseph Redmon | 최초의 단일 CNN 기반 실시간 감지 |
| YOLOv4 | Alexey Bochkovskiy | CSPNet, Mish 활성화, Mosaic |
| YOLOv5 | Ultralytics | PyTorch 전환, export 용이 |
| YOLOv6 | Meituan | Anchor-free, RepVGG 백본 |
| YOLOv7 | Wang Chien-Yao | E-ELAN 구조, Task-decoupled head |
| YOLOv8 | Ultralytics | BackBone 통합, 추적기 내장, Python API |
| **YOLOv11** | Ultralytics 기반 커뮤니티 실험 | RT-DETR 일부 차용, 경량화 중점 |
| **YOLOv12** | 멀티모달·세분화 확장 버전 | CLIP 연동, 세그멘테이션, 트랜스포머 도입 |

---

## YOLOv11의 핵심 기술

YOLOv11은 YOLOv8 기반으로 모바일 및 실시간 AI 환경에 최적화된 커스텀 모델입니다.

### 🧩 구조적 특징
- EfficientRepLite + C2f 구조
- Decoupled Detection Head → 분류/회귀 분리로 정확도 향상
- SPP-Fast 모듈 (Spatial Pyramid Pooling 경량 버전)
- 입력 해상도 자동 조정 (Auto-shape)

### ⚙️ 기술 구성

| 구성 요소 | 내용 |
|-----------|------|
| 백본 | CSPDarknet-lite or MobileNet backbone |
| 중간 neck | PANet or BiFPN (경량화 버전) |
| 헤드 | Decoupled Head + NMS 또는 Soft-NMS |
| 최적화 | ONNX, TensorRT 내보내기 호환성 |

---

## YOLOv12의 기술 진화

YOLOv12는 기존 YOLO 시리즈에서 벗어나, Transformer, 세그멘테이션, 멀티모달 인식 등 최신 딥러닝 기술을 통합한 확장 아키텍처입니다.

### 🚀 기술적 특징
- CLIP/BLIP 기반 텍스트 조건부 객체 인식 지원
- Vision Transformer 일부 연동
- YOLO-SAM (Segmentation-Aware Module) 내장
- "Prompt-driven Detection" 가능성
- ROIAlign 기반 세분화 후처리

### 🔍 멀티태스킹 구조

| Task | 포함 여부 |
|------|------------|
| 객체 감지 (bbox) | ✅ |
| 인스턴스 세그멘테이션 | ✅ |
| 라벨 없는 Zero-Shot 분류 | ✅ |
| 트래킹 | ✅ |

---

## 구조적 차이점

| 항목 | YOLOv11 | YOLOv12 |
|------|---------|---------|
| 백본 | EfficientRep / CSPDarknet | ConvNext-lite or Hybrid Transformer |
| 헤드 | Decoupled head | Unified Multi-head (Seg + Det) |
| 입력 스케일 | 고정 또는 Resize | 다중 해상도 동시 학습 |
| Anchor 사용 | ✅ 일부 | ❌ Anchor-Free 확정 |
| 모델 크기 | ~35M | ~50M 이상 |
| FLOPs | 낮음 | 높음 |

---

## 성능 벤치마크 (추정)

> COCO 2017 기준, 동일 환경(T4 GPU, 640px 입력 기준)

| 항목 | YOLOv11 | YOLOv12 |
|------|---------|---------|
| mAP@0.5 | 53.2% | **55.9%** |
| mAP@0.5:0.95 | 34.1% | **38.6%** |
| FPS (GPU) | **120+** | 90~100 |
| 파라미터 수 | 약 35M | 약 52M |
| 학습 속도 | 빠름 | 느림 |

---

## 훈련 기법 및 최적화 전략

| 항목 | YOLOv11 | YOLOv12 |
|------|---------|---------|
| Data Augmentation | Mosaic v2, MixUp | Copy-Paste, DenseAug |
| 손실 함수 | CIoU Loss | DIoU + Auxiliary Loss |
| 사전 학습 | COCO + Custom | COCO + CLIP Pretrain |
| 옵티마이저 | AdamW / SGD | AdamW + OneCycle |
| 라벨 자동화 | ❌ 없음 | ✅ 가능 (Text Prompt 기반) |

---

## 사용 사례 비교

| 분야 | YOLOv11 | YOLOv12 |
|------|---------|---------|
| 스마트 CCTV | ✅ 빠른 추론 적합 | ✅ 고정밀 이상 행동 인식 |
| 자율주행 | ✅ 임베디드 탑재 | ✅ 객체 세분화 지원 |
| 드론 비행체 추적 | ✅ 실시간 처리 강점 | ⚠️ 느린 추론 주의 |
| 로봇 비전 | ✅ 경량화 장점 | ✅ 복합 인식 가능 |
| 리서치/모달 융합 | ❌ 부적합 | ✅ 추천 (멀티모달 연구용) |

---

## 기술적 한계 및 개선 방향

### YOLOv11의 한계
- Zero-shot 학습 불가
- 객체 마스킹 불가 (BBox 한정)
- 복잡한 장면에서 오탐지 증가

### YOLOv12의 한계
- 무겁고 추론 속도 느림
- 멀티모달 연동을 위한 추가 메모리 필요
- 파라미터 수 급증으로 경량 AI에는 부적합

---

## 결론 및 추천

| 상황 | 추천 모델 |
|------|------------|
| 모바일·IoT 디바이스 | **YOLOv11** |
| 고정밀, 복합 감지 | **YOLOv12** |
| 연구용 실험 | YOLOv12 |
| 상용 실시간 앱 | YOLOv11 |
| 객체 분리·추적·세분화 | YOLOv12 |

YOLOv11은 속도와 효율성에 집중한 실용형 모델이며,  
YOLOv12는 최신 비전·언어 통합 기술을 적용한 연구 중심 모델입니다.

